{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review response generation (demo)\n",
    "\n",
    "This is a demo script for automatic response generation models trained with Fairseq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "# set device\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"  # specify which GPU(s) to be used\n",
    "\n",
    "from typing import List, Optional\n",
    "\n",
    "import torch\n",
    "from fairseq import bleu, checkpoint_utils, data, options, tasks, utils\n",
    "from fairseq.data import encoders\n",
    "from fairseq.logging.meters import StopwatchMeter\n",
    "\n",
    "\n",
    "# from fairseq.models.rrgen_seq2seq_lstm import rrgen_lstm_arch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define arguments and load model for generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from /srv/scratch2/kew/fairseq_materials/rrgen/de/ft100_rg/checkpoints/checkpoint_best.pt\n",
      "finished loading model from /srv/scratch2/kew/fairseq_materials/rrgen/de/ft100_rg/checkpoints/checkpoint_best.pt\n"
     ]
    }
   ],
   "source": [
    "# Parse command-line arguments for generation\n",
    "parser = options.get_generation_parser(default_task='rrgen_translation')\n",
    "\n",
    "# test (small) model\n",
    "# input_args = [\n",
    "#     '/srv/scratch2/kew/fairseq_materials/translation_format/raw',\n",
    "#     '--path=/srv/scratch2/kew/fairseq_materials/translation_format/rrgen_lstm_emb_senti_cate_rate_100k/checkpoints/checkpoint_best.pt',\n",
    "#     '-s=src',\n",
    "#     '-t=tgt',\n",
    "#     '--task=rrgen_translation',\n",
    "#     '--dataset-impl=raw',\n",
    "#     '--nbest=1',\n",
    "#     '--beam=10',\n",
    "# #     '--sampling',\n",
    "# #     '--sampling-topp=0.9',\n",
    "#     '--use-sentiment=senti',\n",
    "#     '--use-category=cate',\n",
    "#     '--use-rating=rate',\n",
    "# ]\n",
    "\n",
    "input_args = [\n",
    "    '/srv/scratch2/kew/fairseq_materials/rrgen/de/data_bin_rg',\n",
    "#     '--path=/srv/scratch2/kew/fairseq_materials/rrgen/de/ft100src_rg/checkpoints/checkpoint_best.pt',\n",
    "    '--path=/srv/scratch2/kew/fairseq_materials/rrgen/de/ft100_rg/checkpoints/checkpoint_best.pt',\n",
    "    '-s=review',\n",
    "    '-t=response_rg',\n",
    "    '--task=rrgen_translation',\n",
    "    '--dataset-impl=mmap',\n",
    "    '--nbest=1',\n",
    "    '--beam=5',\n",
    "    '--sampling',\n",
    "    '--sampling-topk=10',\n",
    "#     '--sampling-topp=0.98',\n",
    "    '--use-sentiment=sentiment',\n",
    "    '--use-category=domain',\n",
    "    '--use-rating=rating',\n",
    "]\n",
    "\n",
    "args = options.parse_args_and_arch(parser, input_args=input_args)\n",
    "\n",
    "# Set device\n",
    "# use_cuda = torch.cuda.is_available() and not args.cpu\n",
    "use_cuda = False\n",
    "\n",
    "# Setup task\n",
    "task = tasks.setup_task(args)\n",
    "\n",
    "# Load model\n",
    "print('loading model from {}'.format(args.path))\n",
    "models, _model_args = checkpoint_utils.load_model_ensemble(\n",
    "    [args.path], task=task)\n",
    "model = models[0]\n",
    "\n",
    "print('finished loading model from {}'.format(args.path))\n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "# Load alignment dictionary for unknown word replacement\n",
    "# (None if no unknown word replacement, empty if no path to align dictionary)\n",
    "align_dict = utils.load_align_dict(args.replace_unk)\n",
    "\n",
    "# initialise generator model\n",
    "generator = task.build_generator(models, args)\n",
    "\n",
    "# Handle tokenization and BPE\n",
    "tokenizer = encoders.build_tokenizer(args)\n",
    "bpe = encoders.build_bpe(args)\n",
    "\n",
    "def decode_fn(x):\n",
    "    if bpe is not None:\n",
    "        x = bpe.decode(x)\n",
    "    if tokenizer is not None:\n",
    "        x = tokenizer.decode(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(sentence: str,\n",
    "                 ext_senti: Optional[int] = None,\n",
    "                 ext_cate: Optional[str] = None,\n",
    "                 ext_rate: Optional[int] = None,\n",
    "                 target: Optional[str] = None,\n",
    "                ):\n",
    "\n",
    "    # vectorize input sentence \n",
    "    tokens = task.source_dictionary.encode_line(\n",
    "    sentence, add_if_not_exist=False,)\n",
    "\n",
    "    print(args)\n",
    "    \n",
    "    if args.use_sentiment:\n",
    "        try:\n",
    "            ext_senti = task.ext_senti_dict[ext_senti]\n",
    "        except:\n",
    "            try:\n",
    "                ext_senti = task.ext_senti_dict[int(ext_senti)]\n",
    "            except:\n",
    "                r = random.choice(list(task.ext_senti_dict))\n",
    "                print(f'[!] WARNING: Could not find value for sentiment input {ext_senti}. Using sentiment value {r}')               \n",
    "                ext_senti = task.ext_senti_dict[r]\n",
    "    if args.use_category:\n",
    "        try:\n",
    "            ext_cate = task.ext_cate_dict[ext_cate]\n",
    "        except:\n",
    "            try:\n",
    "                ext_cate = task.ext_cate_dict[int(ext_cate)]\n",
    "            except:\n",
    "                r = random.choice(list(task.ext_cate_dict))\n",
    "                print(f'[!] WARNING: Could not find value for category input {ext_cate}. Using category value {r}')               \n",
    "                ext_cate = task.ext_cate_dict[r]\n",
    "    if args.use_rating:\n",
    "        try:\n",
    "            ext_rate = task.ext_rate_dict[ext_rate]\n",
    "        except:\n",
    "            try:\n",
    "                ext_rate = task.ext_rate_dict[int(ext_rate)]\n",
    "            except:\n",
    "                r = random.choice(list(task.ext_rate_dict))\n",
    "                print(f'[!] WARNING: Could not find value for category input {ext_rate}. Using rating value {r}')               \n",
    "                ext_rate = task.ext_rate_dict[r]\n",
    "                \n",
    "    # collate input as batch of size 1\n",
    "    batch = data.rrgen_dataset.collate(\n",
    "    samples=[{\n",
    "        'id': -1,\n",
    "        'source': tokens,\n",
    "        'ext_senti': ext_senti,\n",
    "        'ext_rate': ext_rate,\n",
    "        'ext_cate': ext_cate\n",
    "    }],\n",
    "    pad_idx=task.source_dictionary.pad(),\n",
    "    eos_idx=task.source_dictionary.eos(),\n",
    "    left_pad_source=False,\n",
    "    input_feeding=False)\n",
    "\n",
    "    # [!] ensure correct dtype (int64)\n",
    "    batch['net_input']['src_tokens'] = batch['net_input']['src_tokens'].type(\n",
    "        torch.LongTensor)\n",
    "\n",
    "    batch = utils.move_to_cuda(batch) if use_cuda else batch\n",
    "    \n",
    "    # assume no prefix tokens to initialise decoded output\n",
    "    prefix_tokens = None\n",
    "    \n",
    "    gen_timer = StopwatchMeter()\n",
    "    gen_timer.start()\n",
    "    # target_tokens = None\n",
    "    hypos = task.inference_step(generator, model, batch, prefix_tokens)\n",
    "    num_generated_tokens = sum(len(h[0]['tokens']) for h in hypos)\n",
    "    gen_timer.stop(num_generated_tokens)\n",
    "    \n",
    "    device = 'GPU' if use_cuda else 'CPU'\n",
    "    \n",
    "    \n",
    "    # Process top predictions\n",
    "    for j, hypo in enumerate(hypos[0][:args.nbest]):\n",
    "        hypo_tokens, hypo_str, alignment = utils.post_process_prediction(\n",
    "            hypo_tokens=hypo['tokens'].int().cpu(),\n",
    "            src_str=tokens,\n",
    "            alignment=hypo['alignment'],\n",
    "            align_dict=align_dict,\n",
    "            tgt_dict=task.target_dictionary,\n",
    "            remove_bpe=args.remove_bpe,\n",
    "            # extra_symbols_to_ignore=get_symbols_to_strip_from_output(generator),\n",
    "        )\n",
    "        detok_hypo_str = decode_fn(hypo_str)\n",
    "        \n",
    "        print(detok_hypo_str)\n",
    "        print()\n",
    "        \n",
    "        if target:\n",
    "            # Generate and compute BLEU score\n",
    "            if args.sacrebleu:\n",
    "                scorer = bleu.SacrebleuScorer()\n",
    "            else:\n",
    "                scorer = bleu.Scorer(\n",
    "                    task.target_dictionary.pad(),\n",
    "                    task.target_dictionary.eos(),\n",
    "                    task.target_dictionary.unk())\n",
    "            \n",
    "#             if align_dict is not None or args.remove_bpe is not None:\n",
    "                # Convert back to tokens for evaluation with unk replacement and/or without BPE\n",
    "            target_tokens = task.target_dictionary.encode_line(target, add_if_not_exist=True)\n",
    "            hypo_tokens = task.target_dictionary.encode_line(detok_hypo_str, add_if_not_exist=True)\n",
    "            \n",
    "            if hasattr(scorer, 'add_string'): # i.e. if using SacreBLEU\n",
    "                scorer.add_string(target, detok_hypo_str)\n",
    "            else:\n",
    "                scorer.add(target_tokens, hypo_tokens) # calculate n-gram overlap on vectorized texts \n",
    "            \n",
    "            print(scorer.result_string())\n",
    "            \n",
    "    \n",
    "    print('Generated {} response(s) ({} tokens) in {:.1f}s on {}\\n'.format(\n",
    "        len(hypos[0][:args.nbest]), gen_timer.n, gen_timer.sum, device))\n",
    "    \n",
    "    print('-'*80)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Generate review responses with loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(all_gather_list_size=16384, beam=5, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', cpu=False, criterion='cross_entropy', data='/srv/scratch2/kew/fairseq_materials/rrgen/de/data_bin_rg', data_buffer_size=10, dataset_impl='mmap', ddp_backend='c10d', decoding_format=None, device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source=True, left_pad_target=False, lenpen=1, load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_sentences=None, max_source_positions=1024, max_target_positions=1024, max_tokens=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, momentum=0.99, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, no_seed_provided=True, nprocs_per_node=7, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='nag', path='/srv/scratch2/kew/fairseq_materials/rrgen/de/ft100_rg/checkpoints/checkpoint_best.pt', prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sampling=True, sampling_topk=10, sampling_topp=-1.0, score_reference=False, seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='review', target_lang='response_rg', task='rrgen_translation', temperature=1.0, tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, tpu=False, truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, use_category='domain', use_length=None, use_rating='rating', use_sentiment='sentiment', user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
      "Grüezi \" <NAME> \" ganz herzlichen Dank für ihre tolle Bewertung . es freut uns sehr dass ihnen ihr Besuch bei uns gefallen hat ! <SALUTATION>\n",
      "\n",
      "Generated 1 response(s) (27 tokens) in 3.7s on CPU\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Restaurant (positive)\n",
    "review = \"\"\"\n",
    "grosszügiges mittagsmenu ---SEP--- sehr freundliches Personal , \n",
    "tolles Ambiente und ein grosszügiges Mittagsmenu zu einem angemessenem Preis .\n",
    "\"\"\"\n",
    "\n",
    "target=\"\"\"\n",
    "<GREETING> besten Dank für ihre tolle Bewertung zu ihrem Aufenthalt\n",
    "von gestern Mittag bei uns im Sapori . Zeilen wie ihre sind die beste\n",
    "Motivation für unsere Mitarbeiter - Merci ! wir freuen uns , durch die\n",
    "Passion unserer Mitarbeiter unsere Gäste täglich aufs Neue zu überrschen\n",
    "und zu begeistern ! wir wünschen ihnen alles Gute uns freuen uns , \n",
    "sie bei einer baldigen Gelegenheit erneut bei uns begrüssen und \n",
    "kulinairsch verwöhnen zu dürfen .\n",
    "\"\"\"\n",
    "\n",
    "sentiment = 8\n",
    "\n",
    "rating = 5\n",
    "\n",
    "domain = 2\n",
    "\n",
    "get_response(\n",
    "    sentence=review, \n",
    "    ext_senti=sentiment, \n",
    "    ext_cate=domain, \n",
    "    ext_rate=rating, \n",
    "#     target=target\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<GREETING> , wir bedanken uns für ihren Besuch im Clouds und ihre Zeit die sie sich für eine Rückmeldung genommen haben . wir bedauern sehr , dass wir sie nicht von unserem Restaurant überzeugen konnten . <SALUTATION>\n",
      "\n",
      "Generated 1 response(s) (38 tokens) in 2.8s on CPU\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Restaurant (negative)\n",
    "review = \"\"\"\n",
    "selten so schlechten Burger gegessen ---SEP--- \n",
    "überteuert , schlechte Qualität , Essen teilweise kalt , \n",
    "Bedienung unfreundlich und überfordert , es hat gezogen ohne Ende\n",
    "\"\"\"\n",
    "\n",
    "target=\"\"\"\n",
    "<GREETING> , wir sind immer offen für Kritik und nehmen diese in der Regel sehr ernst . ihre Kritik hingegen empfinden wir teilweise als ungerecht . wir haben unser Restaurant vor ca. <DIGIT> Wochen eröffnet und wissen , das es im Servicebereich leider noch nicht so läuft wie wir uns das wünschen und wie es normalerweise unser Anspruch ist . daran arbeiten wir und entschuldigen uns . auch kennen wir die Problematik , das es gezogen hat , dies wurde nun endlich behoben . nicht nachvollziehen können wir ihre Kritik zu den Preisen und zur Qualität und dagegen verwehren wir uns deutlich . wir verwenden <DIGIT> - <DIGIT> g Rindfleisch bester Qualität bei unseren Burgern . unsere Brötchen werden jeden Tag nach unseren Vorgaben frisch für uns gebacken . alle unsere Soßen werden jeden Tag aus besten Zutaten frisch zubereitet . wir verwenden nur frische Produkte und legen größten Wert auf die Qualität . Geschmäcker sind unterschiedlich und leider können wir trotz größter Bemühungen nicht den Geschmack von jedem treffen , das merken wir immer wieder bei unseren hausgemachten , frischen Soßen . nichts desto trotz ist unsere Preisgestaltung im Vergleich zur Menge und Qualität sehr günstig . wir freuen uns auf ihren nächsten Besuch in einem unserer Restaurants mit einer objektiveren Betrachtungsweise . <SALUTATION>\n",
    "\"\"\"\n",
    "\n",
    "sentiment = 2\n",
    "\n",
    "rating = 2\n",
    "\n",
    "domain = 1\n",
    "\n",
    "get_response(\n",
    "    sentence=review, \n",
    "    ext_senti=sentiment, \n",
    "    ext_cate=domain, \n",
    "    ext_rate=rating, \n",
    "#     target=target\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hotel (positive)\n",
    "review = \"\"\"\n",
    "Ibis Styles Wien City ---SEP--- Top Hotel , Super freundlich ; \n",
    "sauber und gepflegt . Ecksuite Super Hell , Fön auf dem Zimmer \n",
    "Wasserkocher wäre nicht schlecht . kostenloser Kaffeeautomat und \n",
    "Wasserspender in der Lobby Frühstück reichhaltig und vielfältig\n",
    "\"\"\"\n",
    "\n",
    "target=\"\"\"\n",
    "<GREETING> , was für eine Bewertung ! vielen Dank dafür ! es macht \n",
    "mich und das gesamte Ibis Team sehr glücklich , dass sie und ihre \n",
    "Familie ihren Aufenthalt bei uns genossen haben . vielen Dank auch \n",
    "für die Anregung betreffend dem Wasserkocher - diesen bieten wir \n",
    "bereits gerne nach Verfügbarkeit an der Rezeption zum Verleih an . <SALUTATION>\n",
    "\"\"\"\n",
    "\n",
    "sentiment = 9\n",
    "\n",
    "rating = 5\n",
    "\n",
    "domain = 1\n",
    "\n",
    "get_response(\n",
    "    sentence=review, \n",
    "    ext_senti=sentiment, \n",
    "    ext_cate=domain, \n",
    "    ext_rate=rating, \n",
    "    target=target\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hotel (negative)\n",
    "review = \"\"\"\n",
    "schlechtes Hotel ---SEP--- das Hotel hatte keine funktionierende \n",
    "Klimaanlage , trotzdem wurde der volle Preis berechnet , Personal \n",
    "größtenteils unfreundlich und nicht hilfsbereit . dreckiges Zimmer\n",
    "und alt , Fenster teilweise nicht zu öffnen\n",
    "\"\"\"\n",
    "\n",
    "target=\"\"\"\n",
    "<GREETING> , vielen Dank für ihre Zeit und ihre Bewertung . \n",
    "wir schätzen sie als unseren Gast , und ihr Feedback ist uns sehr wichtig . \n",
    "indem sie uns mitteilen , was ihnen an ihrem Aufenthalt gefallen hat und \n",
    "was wir noch verbessern können , unterstützen sie uns dabei , den Aufenthalt \n",
    "bei uns für sie und andere Gäste zukünftig noch angenehmer zu gestalten . \n",
    "derzeit finden Renovierungsarbeiten statt . wir danken für das Verständnis , \n",
    "dass wir dies bei laufendem Betrieb nur nach und nach vollrichten können . \n",
    "eine Klimaanlage ist in unserem Hotel bisher nicht vorhanden gewesen . \n",
    "im Zuge der Renovierung wird diese erst eingebaut . \n",
    "wir freuen uns schon heute , sie bald wieder bei uns begrüßen \n",
    "zu können . <SALUTATION>\n",
    "\"\"\"\n",
    "\n",
    "sentiment = 2\n",
    "\n",
    "rating = 2\n",
    "\n",
    "domain = 1\n",
    "\n",
    "get_response(\n",
    "    sentence=review, \n",
    "    ext_senti=sentiment, \n",
    "    ext_cate=domain, \n",
    "    ext_rate=rating, \n",
    "    target=target\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"\n",
    "das Allerletzte ---SEP--- wir haben bereits vor Monaten \n",
    "zwei Doppelzimmer mit getrennten Betten gebucht , \n",
    "die Kreditkarte wurde lange vor der Ankunft belastet , \n",
    "obwohl die Zimmer bezahlt sind wird die Kreditkarte bei \n",
    "der Ankunft noch einmal mit <DIGIT> Euro Garantie belastet \n",
    "( mehr als der Preis der bereits bezahlten Übernachtungen ) , \n",
    "bei der Ankunft im Hotel ist die Reception völlig überlaufen , \n",
    "Wartezeit eine halbe Stunde , die reservierten und bezahlten \n",
    "Zimmer stehen nicht zur Verfügung , das Hotel sei ausgebucht , \n",
    "wir bekommen lediglich zwei Zimmer mit kleinen Doppelbetten , \n",
    "ein Zimmer nicht sehr sauber , es liegt im Eingangsbereich \n",
    "Müll auf dem Boden , das ganze ist eine Zumutung , \n",
    "Personal an der Rezeption genervt und unfreundlich , \n",
    "dieses Hotel besser meiden , \n",
    "P.S. : in der Hotelhalle ist auch noch Erbrochenes auf dem Fußboden\n",
    "\"\"\"\n",
    "target = \"\"\"\n",
    "<GREETING> W , vielen Dank für ihren Aufenthalt und für die Zeit ,\n",
    "die sie sich genommen haben um uns dieses Feedback zu schreiben .\n",
    "wir möchten uns natürlich für den negativen Eindruck ,\n",
    "den sie hier offensichtlich bekommen haben entschuldigen .\n",
    "da uns die Zufriedenheit unserer Gäste sehr am Herzen liegt ,\n",
    "möchten wir der Sache gerne auf den Grund gehen und bitten sie daher ,\n",
    "uns persönlich per E-Mail zu kontaktieren ,\n",
    "damit wir in diesem Fall recherchieren können .\n",
    "dies dient zum einen zur internen Verbesserung ,\n",
    "zum anderen möchten wir ihnen natürlich gerne zeigen ,\n",
    "dass wir es besser können und eine Lösung für diese Herausforderung finden .\n",
    "wir freuen uns auf ihre Rückmeldung .\n",
    "\"\"\"\n",
    "senti = 1\n",
    "cate = 1\n",
    "rate = 1\n",
    "\n",
    "get_response(sentence=review, ext_senti=senti, ext_cate=cate, ext_rate=rate, target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"\n",
    "das war das letzte Mal ---SEP--- unprofessionelle , \n",
    "aggressive und gewalttätige Tür ohne jede Klasse und \n",
    "ohne die Fähigkeit gewaltfrei zu deeskalieren\"\"\"\n",
    "target = \"\"\"\n",
    "<GREETING> , wir bedauern sehr , dass sie so unangenehme\n",
    "eine Erfahrung bei uns machen Mussten . schreiben sie uns\n",
    "sehr gerne eine E-Mail an <EMAIL> , damit wir mehr Details\n",
    "über diesen Abend erfahren und gemeinsam eine Lösung finden können . <SALUTATION>\"\"\"\n",
    "senti = 1\n",
    "cate = 2\n",
    "rate = 1\n",
    "get_response(sentence=review, ext_senti=senti, ext_cate=cate, ext_rate=rate, target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"leider sehr enttäuschend ---SEP--- wir waren \n",
    "an einem sonnigen Donnerstagabend auf der Terrasse von The Butcher .\n",
    "auf unsere Speisekarte mussten wir erst einmal <DIGIT> Minuten warten ,\n",
    "die Bedienung erklärte uns , dass Zurzeit keine Karten verfügbar seien .\n",
    "die Bedienung war zwar freundliche , wirkte jedoch gestresst , \n",
    "weil alle Tische besetzt waren . \n",
    "wir bestellten zwei vegane Burger , da drei der vegetarischen Burger\n",
    "laut Karte Vegan zubereitet werden könne . die Bedienung erklärte uns dann aber ,\n",
    "dass dies nur bei einem Burger möglich sei . \n",
    "als die Burger nach einer halben Stunde serviert wurden , enthielten sie Käse .\n",
    "also schickten wir sie zurück in die Küche . \n",
    "nach einer Viertelstunde kamen die Burger zurück - diesmal mit einem \" V \" gekennzeichnet .\n",
    "sie enthielten noch immer Käse . erst nach insgesamt <DIGIT> Stunden Wartezeit\n",
    "erhielten wir schliesslich die bestellten veganen Burger , \n",
    "dabei handelte es sich aber eher um ein Brötchen mir Gemüse ohne Sauce . ich habe Verständnis dafür , dass nicht in jedem Restaurant Vegan gegessen werden kann . wer dies aber auf die Karte schreibt , sollte doch wenigstens wissen , was Vegan bedeutet . auch irritierend fand ich , dass ein Burger-Restaurant , das auf der Karte damit wirbt , besonders nachhaltig zu sein , alle Getränke im Plastik-Becher serviert . nachhaltig geht anders .\"\"\"\n",
    "senti = 2 # 7\n",
    "cate = 2\n",
    "rate = 1\n",
    "\n",
    "get_response(sentence=review, ext_senti=senti, ext_cate=cate, ext_rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"falsche Zusagen ( schriftlich ) ---SEP--- unsere Anreise erfolgte gegen <DIGIT> Uhr mit <DIGIT> müden Kindern nach einer <DIGIT> stündigen Autofahrt . ich wurde noch begrüßt , mein Mann der <DIGIT> Min später nach kam nicht ( kein Problem ) . vor der Buchung wurde uns schriftlich ein Doppelzimmer mit Verbindungstür bestätigt . vor Ort , wusste keiner etwas davon . Kinderzimmer auf einer Etage , Elternschlafzimmer auf einer anderen ! ? ? ? nach eindringlichem Bitten eine Lösung zu finden , wurde mir gesagt sie seien ausgebucht und das ist eben so ! ? ich habe wehement darum gebeten eine Lösung zu finden - beide angestellte <DIGIT> Min weg ! ? dann wurde mir gesagt , sie versuchen es- kann dauern ..... auf meine Frage , wie lange ( mittlerweile <DIGIT> Uhr ) war die Antwort - keine Ahnung 🤔 . unfassbar wie Unprofessionell . nach eindringlichem Bitten mir eine ungefähre Zeit zu nennen , <DIGIT> Min , <DIGIT> Min oder eine Stunde wurde mir gesagt eher 1stunde . ich habe dankend abgelehnt und darum gebeten den Vorgang zu stornieren . ich hätte dieses Hotel niemals ohne Zusage der Verbindungstür gewählt . vor Ort waren die Mitarbeiter echt frech und ignorant - ich bin schwer enttäuscht . das einzig positive , das sie den Vorgang ohne Kosten storniert haben\"\"\"\n",
    "senti = 1\n",
    "cate = 1\n",
    "rate = 1\n",
    "\n",
    "get_response(sentence=review, ext_senti=senti, ext_cate=cate, ext_rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"Miserabel ---SEP--- im Hotel Seiler ist das Wort Kulanz nicht existent . wir hätten wenigstens ein Entgegenkommen in Form.Z . b.eines Gutscheines erwartet . das Hotel Seiler haben wir aus unserer Liste gestrichen . wir werden auch entsprechend Werbung für das Haus machen .\"\"\"\n",
    "senti = 4\n",
    "cate = 1\n",
    "rate = 1\n",
    "get_response(sentence=review, ext_senti=senti, ext_cate=cate, ext_rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"stinkend statt dufte ---SEP--- das gesamte Hotel eoch nach Toilette , da es ein paar Wochen zuvor ein Abwasser-Rohrbruch gab . das Badwar ungenügend geputzt und die Klimaanlage ließ sich nicht regeln . das Zimmer war sehr warm . das Personal am Check-In lehnte eine Reklamation ab und wies mehrere Gäste in arroganter und unfreundlicher Weise ab .\"\"\"\n",
    "senti = 3 #7\n",
    "cate = 1\n",
    "rate = 1\n",
    "get_response(sentence=review, ext_senti=senti, ext_cate=cate, ext_rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"enttäuschend ---SEP--- der Wein ( Pinot Grigio und Frascati ) war absolut nicht zu empfehlen , billige No-Name Ware , das Essen geschmacklos ( Pizza Frutti Di Mare mit Meeresfrüchte-Imitat aus Surimi ) . die Damen im Service freundlich jedoch der Patrone beim Bezahlen der Rechnung unfreundlich und arrogant . nie wieder !\"\"\"\n",
    "senti = 3\n",
    "cate = 2\n",
    "rate = 1\n",
    "get_response(sentence=review, ext_senti=senti, ext_cate=cate, ext_rate=rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"es war besser als befriedigend aber nicht sehr gut ---SEP--- Gesamteindruck super , Preise für Garage und Frühstück sind generell in allen Hotels zu hoch . Preis / Nacht wäre besser zu akzeptieren wenn es Fitness/Wellness O.Ä. geben würde . dazu könnten Z.B. Info ´ s zu Partnern ausliegen .\"\"\"\n",
    "senti = 6\n",
    "cate = 1\n",
    "rate = 3\n",
    "get_response(sentence=review, ext_senti=senti, ext_cate=cate, ext_rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"Weihnachten im Parkhotel lindner Oberstaufen ---SEP--- unvergessliche Weihnachtsatmosphäre im Parkhotel Lindner , zusammen feiern in einer grossen Familie , sehr gediegen mit Harfenmusik , Weihnachtsgeschichten hören und zusammen Weihnachtslieder singen unter einem wunderbar geschmückten Baum , das war Weihnachten <DIGIT> . das freundliche aufgestellte Personal verwöhnte uns Gäste mit auserlesenen Speisen aus der Küche von Herrn Wagenblast . es war einmal mehr ein unvergesslicher Aufenthalt .\"\"\"\n",
    "senti = 8\n",
    "cate = 1\n",
    "rate = 5\n",
    "get_response(sentence=review, ext_senti=senti, ext_cate=cate, ext_rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
